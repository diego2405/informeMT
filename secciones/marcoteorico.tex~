\documentclass[../memoria.tex]{subfiles}
\begin{document}
\label{marco teorico}

\indent Un sistema típico de Re-ID tiene dos fases: (1) captura de descriptores y (2) comparación de descriptores \cite{bedagkar2014survey}. En la figura \ref{fig:sistemaReID} se puede ver una representación esquemática de un sistema de Re-ID, mostrando las dos etapas mencionadas anteriormente y los sub-procesos dentro de cada una.

\begin{figure}[h!]
  \centering
  \includegraphics[width=\textwidth]{diagrama1.png}
  \caption{Sistema de Re-ID \cite{bedagkar2014survey}}
  \label{fig:sistemaReID}
\end{figure}

\indent En la primera fase, se extrae el descriptor de una persona desde múltiples cámaras (o en nuestro caso, distintas ocurrencias desde una misma cámara), para en la segunda fase establecer la correspondencia entre pares de descriptores, determinando si estos coinciden con la misma persona o son individuos distintos.

\indent Las etapas típicas de la primera fase incluyen \cite{yilmaz2006object}:
\begin{itemize}
\item \underline{Detección de personas:} consiste en establecer la presencia de personas en la escena. %, determinando su ubicación dentro de la imagen y la forma aproximada de cada una de ellas.
Dependiendo de las condiciones del problema, se pueden utilizar diferentes métodos para detectar objetos o personas. Por ejemplo, emplear algoritmos de aprendizaje supervisado cuando se cuenta con una base de datos con imágenes etiquetadas \cite{dalal2005histograms}. En el caso de un video, se tienen varias imágenes consecutivas (cuadros o \emph{frames}), lo que permite detectar cuando la persona se mueve o desplaza por la escena, según los cambios producidos en cada pixel. Lo anterior, es conocido como segmentación entre primer y segundo plano (que corresponden al movimiento y regiones estáticas, respectivamente).

\indent La detección del segundo plano permite eliminar de la imagen todo lo que no forma parte de la persona, aplicando una \emph{máscara} que ocultará todo el conjunto de píxeles que permanezcan sin cambios o inmóviles. Esta máscara consiste en un mapa de bits o matriz de ceros y unos, que se superpone a la imagen original, con el objetivo de convertir todo el segundo plano a un mismo valor (bit cero: color negro), dejando los píxeles del primer plano inalterados (bit uno: color original) \cite{bouwmans2008background}. Seguido a esto, un algoritmo para detectar bordes \cite{canny1986computational} encontrará fronteras entre regiones similares, obteniendo la silueta del objeto o persona en movimiento. En algunas ocasiones, cuando existe alto grado de contraste entre la persona y el fondo (como en una toma la misma altura del individuo) la detección de bordes puede prescindir de la máscara, sin embargo, ésta permite obtener bordes con menos posibilidad de error, dado que todo el fondo tiene un mismo valor \cite{bouwmans2008background}.

\indent Las formas detectadas, en la práctica no siempre se producen por un movimiento real de personas. También se detectarán, por ejemplo, a causa de cambios de iluminación y/o movimiento de otros objetos. Por lo anterior, se requiere un proceso que seleccione una silueta que corresponda a una persona y no a otra cosa. Ésta silueta es reemplazada por una forma geométrica que la contenga (región de interés), la que puede tener forma de rectángulo, elipse, etc \cite{yilmaz2006object}.
%\end{itemize}

\item \underline{Seguimiento de la persona:} seguir la trayectoria realizada por la persona permite inferir datos como la dirección y velocidad de la persona antes de desaparecer. En particular, es de interés el lugar donde aparece y desaparece una persona, para determinar si es alguien que descendió o abordó a un vehículo, o es un peatón no relacionado a un automóvil.

\item \underline{Extracción de características:} de la región de interés, representa por un espacio de colores o una mezcla de varios espacios \cite{gray2008viewpoint}, se extraen datos (características) que formarán una firma (\emph{signature}). Las características pueden ser de distintos tipos, entre ellos: color, forma, posición y textura \cite{vezzani2013people}. 
\begin{itemize}
\item \underline{Color:} una imagen está compuesta por píxeles cuyos valores dependen del espacio de colores empleado. Un espacio de colores está compuesto por varios canales, cada uno de ellos representados en una matriz, cuyos valores están asociados a un pixel de la imagen. Por ejemplo, el espacio RGB está conformado por los canales rojo (R), verde (G) y azúl (B). Otro espacio comúnmente usado es HSV, compuesto por los canales de tonalidad (H), saturación (S) y valor (V). %típicamente descrito con histogramas (vectores de $n$ dimensiones, cada una indicado la cantidad de veces que se repite un valor $i\in[0,n-1]$).%, promedio entre el valor de todos los pixeles, etc.
\item \underline{Forma:} se refiere a datos de la silueta detectada, tales como su altura, ancho, ejes de simetría, relación entre ancho y altura, etc. 
\item \underline{Posición:} cuando los FOV entre cámaras están superpuestos, la posición de la persona dentro de la imagen puede ser utilizada para Re-ID \cite{khan2003consistent, calderara2008hecol}, dado que la posición una persona cambia en el mismo instante y de forma análoga dos o más cámaras.
\item \underline{Textura:} entrega datos de la disposición espacial de los colores de la imagen \cite{stockman2001computervision}. %analizando la imagen en regiones de tamaño fijo, se almacenan los bordes contenidos en ella y la orientacipón de estos (horizontal, vertical, diagonal, etc).
Hay algoritmos \cite{lowe1999object, bay2006surf} que buscan seleccionar ciertos puntos (\emph{keypoints}) en la imagen que sean invariables a cambios de rotación y escala. %donde se encuentre la frontera entre regiones con colores y textura altamente distingibles.  %se caracteriza por puntos específicos en la imagen, donde se se encuentra la frontera entre regiones cuyo patron de bordes sea %al igual que el color, se puede representar con histogramas representada con puntos localizados de la imagen donde se producen cambios notables de colores. Estos puntos se pueden encontrar con algoritmos como SIFT (Scale Invariant Features Transform \cite{[Hu et al. 2008; Zheng et al.2009]}) o SURF (Speeded Up Robust Features\cite{[Hamdoun et al. 2008]}).

%% \begin{itemize}
%% \item \underline{SIFT:} transforma una imagen en una colección de vectores de características, cada una de las cuales son invariantes a traslaciones de la imagen, rotación, escala e iluminación \cite{lowe1999object}. %revisar bib 56-58 de bedekar2014
%% \item \underline{SURF:} \todo{explicación}
%% \end{itemize} 

\end{itemize}

\item \underline{Generación del descriptores:} en este proceso se define la forma de representar las características seleccionadas. Esta representación recibe el nombre de descriptor.
\indent Generalmente se calculan estadísticas sobre las características, para generar una representación sucinta de las características. Por ejemplo, usando de histogramas (vectores de $n$ dimensiones, cada una con la cantidad de veces que se repite un valor $i\in[0,n-1]$). 
%\indent Lo histogramas de colores, por ejemplo, para toda imagen representada en con un mismo espacio de colores. Por ejemplo, cualquier imagen en RGB de 8 bits (256 posibles valores por canal), se emplearán 3 histogramas, uno para cada canal, de dimensión 256. Del mismo modo, en el caso de la textura, se pueden emplear histogramas de arcos, teniendo la cantidad de veces que se repiten cada tipo de arco.
\indent Los descriptores generados pueden ser todos de tamaño fijo o variable. Un ejemplo del primer caso son los histogramas, cuya cantidad de dimensiones es independiente del tamaño de la imagen y los colores presentes en ella, dependiendo el tamaño sólo del espacio de colores empleado. El algoritmo presentado en \cite{lowe1999object} (Scale-invariant feature transform, SIFT) que encuentra keypoints en la imagen, es un ejemplo de descriptores de tamaño variable, ya que la cantidad de puntos seleccionados es variable dependiendo de la complejidad de la imagen. Sin embargo, la representación de cada punto es un vector de tamaño fijo. %Así, el descriptor de una imagen basado en keypoints (también conocidos como \emph{localized features}), puede ser visto como una matriz con cantidada fija de columnas y con tantas filas como puntos se hayan seleccionado de la imagen. 

\indent Por último, se pueden emplear varias imagenes para generar el descriptor de una persona \cite{bedagkar2014survey}, lo que también hace variable el tamaño del descriptor de cada persona. %haciendo que Si bien se tiene un descriptor por cada imagen, en una secuencia de video se cuenta con varios frames por persona, pudiendo generar y asociar más de un descriptor por persona \cite{multishot}. %compuestos por puntos de este tipo se puede% donde la cantidad de puntos obtenidos por imagen es variable, sin embargo, cada punto es de tamaño fijo. %, el descriptor será también de tamaño variable. % para representar colores y texturasLa estructura de dato que contiene el conjunto de características de la imagen es llamada descriptor. El descriptor elegido depende del tipo de característica y la tarea que se desea realizar (detectar, reconocer) las características extraídas son almacenadas en estructuras de datos llamadas descriptores. Un descriptor generalmente consta de una matriz de tamaño fijo con datos correspondientes a los valores de las características elegidas. Dado que tienen el mismo tamaño, se pueden comparar de forma directa con alguna función matemática de distancia para establecer su similitud. 

\item \underline{Comparación de descriptores:} el objetivo de este proceso es establecer si un par de descriptores corresponden o no a la misma persona, dependiendo de la similitud entre descriptores. El parecido es calculado con una función que mida la distancia entre descriptores \cite{gheissari2006person, wang2007shape, farenzena2010person, gray2008viewpoint, bak2010person, lin2008learning, prosser2010person, dalal2005histograms}.

\indent Para encontrar una coincidencia (par de descriptores pertenecientes a la misma persona: \emph{match}) se han propuesto varios algoritmos. Una forma es calcular la distancia euclidiana entre el descriptor consultado (\emph{query}) con todos los posibles candidatos (vecinos) y luego elegir a los $k$ candidatos que se encuentren a menor distancia, técnica conocida como el k-ésimo vecino más cercano (k Nearest Neighbor, k-NN). Una mejora a la técnica anterior es emplear una métrica de distancia aprendida que reemplaza la función de distancia euclidiana por otra que considera patrones estadísticos obtenidos de relaciones par-etiqueta: par compuesto por dos descriptores, y la etiqueta binaria que indica si éstos son un match o no \cite{weinberger2009dml, zheng2013reidentification, dikmen2011pedestrian, hirzer2012person, hirzer2012relaxed, zheng2011person}.

\indent En el caso de la comparación de dos descriptores compuesto por keypoints (ej. SIFT), se calcula la distancia de cada keypoint de un descriptor con todos los keypoints del otro descriptor, estableciendo una correspondencia positiva si existe un par de keypoints a una distancia lo suficientemente pequeña, menor a cierto umbral. Si se cuenta con varias imágenes por persona, un sistema de votación es otra alternativa para elegir el candidato que más se asemeja a la consulta. Se le asigna un voto al descriptor candidato siempre que éste posea el keypoint más similar (a menor distancia) a un keypoint del descriptor consultado, emitiendo tantos votos como keypoints tenga éste, seleccionando luego al descriptor candidato con más votos \cite{hamdoun2008person}. 
\end{itemize}

\end{document}
